# Changes Summary: Model Input & Depth Photo Saving

## Changes Made

### 1. **Removed Rotation from Depth Prompt Processing**
**Previous behavior**: ARKit depth (256Ã—192) was rotated 90Â° CCW â†’ 192Ã—256 before feeding to model

**New behavior**: ARKit depth (256Ã—192) is used directly without rotation

**Files modified**:
- `PromptDAEngine.swift`:
  - Removed all rotation code from `makePromptArray()`
  - Changed from `CGAffineTransform(rotationAngle:)` to direct rendering
  - Added resize support if input doesn't match expected dimensions

### 2. **Updated Model Configuration**
**Previous**: 
- Model name: `PromptDA_vits_518x518_prompt192x256`
- Prompt size: 192Ã—256 (HÃ—W)

**New**:
- Model name: `PromptDA_vits_518x518_prompt256x192`
- Prompt size: 256Ã—192 (HÃ—W)

**Files modified**:
- `PromptDAEngine.swift`: Changed default parameters in `create()`
- `Renderer.swift`: Updated model name and prompt dimensions in initialization

### 3. **Added Depth Photo Saving Feature**

**New functionality**: Save ARKit depth maps as grayscale photos to Photos app

**Implementation**:
- Added `saveDepthPhoto()` public method to trigger save
- Added `saveDepthAsPhoto()` private method to convert and save
- Depth values normalized to 0-255 grayscale range
- Photos saved with sequential numbering
- Automatic permission request

**Files modified**:
- `Renderer.swift`:
  - Imported `Photos` framework
  - Added `depthPhotoCounter` and `shouldSaveNextDepth` properties
  - Added depth saving logic in `updateLiDARDepthTextures()`
  - Created `saveDepthAsPhoto()` method with normalization
- `Info.plist`:
  - Added `NSPhotoLibraryAddUsageDescription` key

## How to Use

### **Trigger Depth Photo Save**
Call from your UI (e.g., MainController):
```swift
@IBAction func saveDepthPhotoButtonTapped(_ sender: UIButton) {
    renderer.saveDepthPhoto()
}
```

The next depth frame will be:
1. Normalized to grayscale (0-255)
2. Converted to UIImage
3. Saved to Photos app
4. Logged with: `âœ… Depth photo #N saved to Photos (256Ã—192)`

### **Expected Console Output**

When depth photo is saved:
```
ðŸ“¸ Saving ARKit depth map as photo...
   â€¢ Depth range: 0.234m - 4.567m
   âœ… Depth photo #1 saved to Photos (256Ã—192)
```

## Model Requirements

### **Old Model** (no longer used):
- Name: `PromptDA_vits_518x518_prompt192x256.mlpackage`
- Inputs:
  - `colorImage`: 518Ã—518 RGB
  - `promptDepth`: [1, 1, 192, 256] (rotated ARKit depth)

### **New Model** (current):
- Name: `PromptDA_vits_518x518_prompt256x192.mlpackage`
- Inputs:
  - `colorImage`: 518Ã—518 RGB
  - `promptDepth`: [1, 1, 256, 192] (direct ARKit depth, no rotation)

**Important**: Make sure your CoreML model expects 256Ã—192 prompt depth!

## Depth Processing Pipeline

### **Before (with rotation)**:
```
ARKit Smoothed Depth (256Ã—192)
    â†“
Rotate 90Â° CCW
    â†“
Depth Prompt (192Ã—256)
    â†“
CoreML Model
```

### **After (no rotation)**:
```
ARKit Smoothed Depth (256Ã—192)
    â†“
Direct Copy (or resize if needed)
    â†“
Depth Prompt (256Ã—192)
    â†“
CoreML Model
```

## Depth Photo Format

- **Resolution**: 256Ã—192 (matches ARKit depth)
- **Format**: 8-bit grayscale PNG
- **Range**: Normalized from actual depth range (e.g., 0.2m - 5.0m) to 0-255
- **Location**: iOS Photos app
- **Naming**: Sequential counter (tracked in `depthPhotoCounter`)

## Permissions

The app will automatically request Photos permission when you call `saveDepthPhoto()` for the first time.

**Info.plist entry**:
```xml
<key>NSPhotoLibraryAddUsageDescription</key>
<string>Save depth map images to Photos.</string>
```

## Debug Output Changes

### **Model Initialization**:
```
ðŸš€ PromptDAEngine Initialization Starting...
   â€¢ Model name: PromptDA_vits_518x518_prompt256x192
   â€¢ RGB input size: 518Ã—518
   â€¢ Prompt depth size: 256Ã—192
   â€¢ Note: Matches ARKit smoothed depth (256Ã—192) directly, no rotation
```

### **Prompt Processing**:
```
      â†’ makePromptArray: input 256Ã—192, using directly (no rotation)
      â†’ Rendering to temp buffer: 256Ã—192
      â†’ Prompt depth stats: min=0.234m, max=4.567m, valid=48234/49152
```

## Testing Checklist

- [ ] Verify model name matches: `PromptDA_vits_518x518_prompt256x192.mlpackage`
- [ ] Check model input shape: `[1, 1, 256, 192]` for promptDepth
- [ ] Add model file to Xcode project target
- [ ] Grant Photos permission when prompted
- [ ] Test depth photo saving in LiDAR mode
- [ ] Verify saved photos appear in Photos app
- [ ] Check console for depth range and save confirmation

## Summary

âœ… **Rotation removed**: ARKit depth used directly (256Ã—192)  
âœ… **Model updated**: Now expects 256Ã—192 prompt (not 192Ã—256)  
âœ… **Photo saving added**: Depth maps saved as grayscale images  
âœ… **Permissions added**: Photos library access configured  
âœ… **Debug enhanced**: Clear logging for depth processing and saving
